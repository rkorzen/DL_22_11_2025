{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-walidacja (cross-validation) to metoda oceny modelu polegajƒÖca na **wielokrotnym dzieleniu danych na czƒô≈õƒá treningowƒÖ i testowƒÖ**, tak aby model by≈Ç sprawdzany na r√≥≈ºnych fragmentach danych. Dziƒôki temu wynik oceny jest bardziej wiarygodny ni≈º w pojedynczym train/test split.\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Jak to dzia≈Ça ‚Äî najpro≈õciej\n",
    "\n",
    "Za≈Ç√≥≈ºmy, ≈ºe masz zbi√≥r danych i chcesz sprawdziƒá, jak dobrze dzia≈Ça Tw√≥j model. Zamiast:\n",
    "\n",
    "* trenowaƒá model na 80% danych,\n",
    "* testowaƒá go na pozosta≈Çych 20%,\n",
    "\n",
    "robisz to **kilka razy na r√≥≈ºnych podzia≈Çach**.\n",
    "\n",
    "---\n",
    "\n",
    "# üîÅ K-fold cross-validation (najpopularniejsza forma)\n",
    "\n",
    "1. **Dzielisz dane na K r√≥wnych czƒô≈õci (fold√≥w)** ‚Äî np. K = 5.\n",
    "2. **W ka≈ºdej iteracji**:\n",
    "\n",
    "   * bierzesz jeden fold jako *testowy*,\n",
    "   * pozosta≈Çe K-1 fold√≥w sƒÖ *treningowe*,\n",
    "   * trenujesz model, mierzysz wynik.\n",
    "3. Powtarzasz K razy, a≈º ka≈ºdy fold pe≈Çni≈Ç rolƒô danych testowych.\n",
    "4. **≈örednia z K wynik√≥w** jest ocenƒÖ modelu.\n",
    "\n",
    "---\n",
    "\n",
    "üì¶ **Przyk≈Çad przy K=5**\n",
    "\n",
    "| Iteracja | Trening      | Test   |\n",
    "| -------- | ------------ | ------ |\n",
    "| 1        | fold 2,3,4,5 | fold 1 |\n",
    "| 2        | fold 1,3,4,5 | fold 2 |\n",
    "| 3        | fold 1,2,4,5 | fold 3 |\n",
    "| 4        | fold 1,2,3,5 | fold 4 |\n",
    "| 5        | fold 1,2,3,4 | fold 5 |\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úîÔ∏è Po co to robimy?\n",
    "\n",
    "Cross-walidacja:\n",
    "\n",
    "* daje **stabilniejszy i mniej losowy wynik** ni≈º jeden podzia≈Ç,\n",
    "* lepiej pokazuje, jak model uog√≥lnia na nowe dane,\n",
    "* redukuje ryzyko, ≈ºe wynik zale≈ºy od niefortunnego splitu.\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Kiedy u≈ºywaƒá?\n",
    "\n",
    "* gdy masz **niewiele danych**,\n",
    "* gdy potrzebujesz **obiektywnej oceny modelu**,\n",
    "* przy por√≥wnywaniu modeli (np. KNN vs. SVM vs. RandomForest),\n",
    "* przy strojenia hiperparametr√≥w (GridSearchCV, RandomizedSearchCV).\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Wa≈ºne odmiany\n",
    "\n",
    "| Rodzaj                    | Opis                                                  |\n",
    "| ------------------------- | ----------------------------------------------------- |\n",
    "| **Stratified K-fold**     | Zachowuje proporcje klas (idealne dla klasyfikacji).  |\n",
    "| **Leave-One-Out (LOOCV)** | Ka≈ºdy element raz jest testem (bardzo kosztowne).     |\n",
    "| **TimeSeriesSplit**       | Do danych szereg√≥w czasowych ‚Äî nie miesza kolejno≈õci! |\n",
    "\n",
    "---\n",
    "\n",
    "# üìå Mini schemat (intuicyjnie)\n",
    "\n",
    "```\n",
    "DANE ‚Üí [train/test] x K ‚Üí wyniki ‚Üí ≈õrednia ‚Üí ocena modelu\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## praktyczny przyk≈Çad cross-validacji** w scikit-learn.\n",
    "\n",
    "\n",
    "1. **Klasyczna K-fold cross-validation**\n",
    "2. **Stratified K-fold** (standard przy klasyfikacji)\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ 1. Klasyczna K-fold cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki pojedynczych fold√≥w: [1.         0.96666667 0.93333333 0.93333333 0.96666667]\n",
      "≈örednia: 0.9600000000000002\n",
      "Odchylenie standardowe: 0.024944382578492935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Dane\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# K-fold: 5 podzia≈Ç√≥w\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"Wyniki pojedynczych fold√≥w:\", scores)\n",
    "print(\"≈örednia:\", scores.mean())\n",
    "print(\"Odchylenie standardowe:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ 2. STRATIFIED K-fold (zalecane dla klasyfikacji)\n",
    "\n",
    "W klasyfikacji proporcje klas muszƒÖ byƒá zachowane w ka≈ºdym foldzie ‚Äî dlatego **StratifiedKFold** jest domy≈õlnie u≈ºywany przez `cross_val_score` przy klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki fold√≥w: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
      "≈örednia: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Stratified K-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(\"Wyniki fold√≥w:\", scores)\n",
    "print(\"≈örednia:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 3. Najkr√≥tsza mo≈ºliwa wersja (automatyczna CV)\n",
    "\n",
    "Tu nie podajesz KFold ‚Äî scikit-learn zrobi stratified K=5 domy≈õlnie:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print(scores, scores.mean())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öôÔ∏è 4. Cross-validacja w regresji\n",
    "\n",
    "Tu zwyk≈Çy KFold (bo nie ma klas):\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
    "\n",
    "print(scores, scores.mean())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Je≈õli chcesz, mogƒô te≈º pokazaƒá:\n",
    "\n",
    "* GridSearchCV z cross-validacjƒÖ,\n",
    "* cross-validacjƒô w TimeSeriesSplit,\n",
    "* por√≥wnanie modeli (np. RF vs SVM vs XGBoost) jednym kodem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
