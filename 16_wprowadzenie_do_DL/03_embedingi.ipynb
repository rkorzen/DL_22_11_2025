{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb46bcbe",
   "metadata": {},
   "source": [
    "# Embeddingi w Uczeniu Maszynowym\n",
    "Embedding to reprezentacja obiektów (np. słów, produktów, użytkowników) w przestrzeni wektorowej o niskim wymiarze. Umożliwia uchwycenie podobieństw semantycznych lub kontekstowych, których nie widać w prostych reprezentacjach.\n",
    "\n",
    "Embeddingi istnieją tylko „na tokenach” i bez tokenizacji nie da się ich użyć."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f2cf9-dfd8-4352-a1c7-d30f246744e3",
   "metadata": {},
   "source": [
    "\n",
    "## Token – co to jest?\n",
    "\n",
    "**Token** to podstawowa jednostka tekstu, na której pracuje model NLP.\n",
    "To „kawałek” zdania zamieniony na liczbę (indeks w słowniku).\n",
    "\n",
    "### Rodzaje tokenów\n",
    "\n",
    "* **słowo** – np. „lubię uczyć się” → `[lubię] [uczyć] [się]`\n",
    "* **znak (litera)** – „kot” → `[k] [o] [t]`\n",
    "* **subword (fragment wyrazu)** – „uczyłbym” → `[uczył] [by] [m]`\n",
    "* **specjalne tokeny** – `<pad>` (padding), `<unk>` (nieznane słowo), `<cls>` (początek zdania)\n",
    "\n",
    "### Token w praktyce\n",
    "\n",
    "1. **Tokenizacja** – tekst dzielimy na tokeny.\n",
    "   „lubię uczyć się pytorch” → `[1, 2, 3, 4]`\n",
    "   (gdzie każdemu słowu przypisany jest numer w słowniku).\n",
    "2. **Embedding** – każdy token (numer) zamieniany jest na wektor liczb.\n",
    "   `[1, 2, 3, 4]` →\n",
    "\n",
    "   ```\n",
    "   [[0.01, -0.02, 0.03],   # token „lubię”\n",
    "    [0.05,  0.01, -0.04],  # token „uczyć”\n",
    "    [0.02,  0.07, -0.01],  # token „się”\n",
    "    [0.09, -0.03, 0.02]]   # token „pytorch”\n",
    "   ```\n",
    "\n",
    "### Podsumowanie\n",
    "\n",
    "* **Token = indeks w słowniku** (np. 2 → „uczyć”).\n",
    "* **Embedding = wektor liczb przypisany do tokenu**, który reprezentuje jego znaczenie w przestrzeni wektorowej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e79ea9",
   "metadata": {},
   "source": [
    "## Dlaczego embeddingi?\n",
    "- **Problem z one-hot encodingiem**: \n",
    "  - wymiar wektora rośnie liniowo wraz z liczbą kategorii (np. dla 50 kategorii dostajemy wektory długości 50, w większości wypełnione zerami),\n",
    "  - brak informacji o podobieństwie między kategoriami (wszystkie są tak samo odległe).\n",
    "  - np. kategorie `1, 2, 3` → one-hot: `[1,0,0]`, `[0,1,0]`, `[0,0,1]`.\n",
    "- **Embeddingi (gęste wektory)**:\n",
    "  - reprezentują każdą kategorię jako wektor w przestrzeni o dużo niższym wymiarze (np. 50 kategorii → embeddingi 4-wymiarowe),\n",
    "  - odległość i kierunek wektorów mogą uchwycić podobieństwo między kategoriami (np. `pies` i `kot` będą bliżej siebie niż `pies` i `samochód`).\n",
    "- **Uczenie embeddingów**:\n",
    "  - embeddingi są **parametrami modelu**,\n",
    "  - są aktualizowane podczas trenowania (uczone end-to-end razem z resztą sieci),\n",
    "  - dzięki temu model sam znajduje „najlepszą” reprezentację kategorii dla zadania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051f97c",
   "metadata": {},
   "source": [
    "## Jak embeddingi działają matematycznie\n",
    "- Każdy obiekt otrzymuje numer (indeks).\n",
    "- Indeks trafia do macierzy `E` o wymiarach `(liczba_kategorii, rozmiar_wektora)`.\n",
    "- Wektor embeddingu to po prostu wiersz macierzy `E` wskazywany przez indeks.\n",
    "- Podczas uczenia gradienty przepływają do odpowiednich wierszy, dzięki czemu wektory uczą się reprezentować relacje między obiektami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d988481",
   "metadata": {},
   "source": [
    "### Przykład: od `one-hot` do embeddingu\n",
    "Załóżmy, że mamy taki mały słownik:\n",
    "\n",
    "```{\"kot\":0, \"pies\":1, \"ryba\":2}``` \n",
    "\n",
    "i rozmiar wektora równy 3. \n",
    "\n",
    "Macierz embeddingu `E` będzie miała kształt `(3, 3)`. \n",
    "\n",
    "Wektor *kot* to odpowiedni wiersz macierzy. \n",
    "\n",
    "Poniżej pokazujemy, jak można wykorzystać prostą tablicę NumPy do symulacji pobierania embeddingów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d887bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2,  0.5, -0.1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab = {\"kot\": 0, \"pies\": 1, \"ryba\": 2}\n",
    "E = np.array([\n",
    "    [0.2, 0.5, -0.1],  # wektor \"kot\"\n",
    "    [0.3, 0.4, -0.2],  # wektor \"pies\"\n",
    "    [-0.1, 0.7, 0.6],  # wektor \"ryba\"\n",
    "])\n",
    "\n",
    "word = \"kot\"\n",
    "idx = vocab[word]\n",
    "vector = E[idx]\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c4f7f",
   "metadata": {},
   "source": [
    "Wynikowy wektor można użyć w dalszych obliczeniach (np. przekazać do warstw liniowych, LSTM czy Transformerów)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504ca00",
   "metadata": {},
   "source": [
    "## Trenowanie embeddingów\n",
    "\n",
    "Jedną z cech embeddingów jest to, że są uczone razem z modelem:\n",
    "\n",
    "1. Inicjalizujemy macierz losowo (lub z pretreningu).\n",
    "2. Przekazujemy indeksy kategorii przez warstwę embedding.\n",
    "3. Strata (np. krzyżowa entropia) aktualizuje konkretne wiersze macierzy.\n",
    "4. Po treningu mamy gęste reprezentacje uchwytujące współwystępowanie i podobieństwa.\n",
    "\n",
    "Embeddingi można również wstępnie wytrenować (Word2Vec, GloVe) i później dostosować do konkretnego zadania."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67909ada",
   "metadata": {},
   "source": [
    "### Embeddingi w TensorFlow\n",
    "\n",
    "W TensorFlow mamy specjalną warstwę `tf.keras.layers.Embedding`, która przyjmuje parametry `input_dim` (rozmiar słownika) oraz `output_dim` (rozmiar wektora). \n",
    "\n",
    "Warto ustawić również `mask_zero=True`, jeśli `0` oznacza padding - czyli wypełnianie pustych miejsc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fa7265-47bc-455e-9a9a-6056ba5ca459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 13:58:59.909896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6ede3-e658-4dac-8391-539782f1b1c8",
   "metadata": {},
   "source": [
    "#### Słownik słów\n",
    "\n",
    "`<pad>` = specjalny token paddingu, zawsze indeks `0`\n",
    "\n",
    "Używa się go, aby \"wypełnić\" krótsze sekwencje do jednakowej długości.\n",
    "\n",
    "Dzięki temu możemy ułożyć zdania w macierz (**batch**), gdzie wszystkie mają tyle samo elementów.\n",
    "\n",
    "Padding to też jest token - tyle, że taki specjalny, który ma swój indeks, ale jest ignorowany w obliczeniach dzięki mask_zero / padding_idx”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4aac1b-cfec-4a74-be73-b000af5a7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {\"<pad>\": 0, \"lubię\": 1, \"uczyć\": 2, \"się\": 3, \"pytorch\": 4, \"tensorflow\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0046c5-2a90-47f6-a026-3288469d18ba",
   "metadata": {},
   "source": [
    "#### zdania zakodowane indeksami (różne długości!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a33565f-e871-4688-996d-b2e4c7fb0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    [1, 2],                # \"lubię uczyć\"\n",
    "    [1, 5],                # \"lubię tensorflow\"\n",
    "    [1, 2, 3, 4],          # \"lubię uczyć się pytorch\"\n",
    "    [1, 2, 3, 5, 4],        # \"lubię uczyć się tensorflow pytorch\"\n",
    "    [1, 4, 1, 5, 1, 2, 3]  # \"lubię pytorch lubię tensorflow lubie uczyć się\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c7819-22dd-4acc-9090-4efd23108263",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3a7eb8-bd0a-4681-8200-a8a3aac6b051",
   "metadata": {},
   "source": [
    "\n",
    "### Co to jest *batch*?\n",
    "\n",
    "Mamy 5 zdań - najdłuższe ma 7 wyrazów. Nasza próbka będzie mieć więc wymiar 5 x 7. Jak zbudujemy z tego macierz wypełnioną paddingami to to będzie batch - próbka\n",
    "\n",
    "* **Batch** = paczka/próbka zbiorcza danych, którą podajemy **naraz** do modelu w jednej iteracji.\n",
    "* Zamiast uczyć model na **pojedynczym zdaniu**, bierzemy kilka naraz, żeby:\n",
    "\n",
    "  1. **przyspieszyć uczenie** (wykorzystujemy równoległość na GPU),\n",
    "  2. **ustabilizować gradienty** (średnia z kilku próbek jest mniej „szarpana” niż z jednej).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c63145-2140-4a19-9d15-c70e75ad15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e793e669-50fe-46ac-a99c-2c0ef8f224f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sekwencje po paddingu:\n",
      " [[1 2 0 0 0 0 0]\n",
      " [1 5 0 0 0 0 0]\n",
      " [1 2 3 4 0 0 0]\n",
      " [1 2 3 5 4 0 0]\n",
      " [1 4 1 5 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- padding do równej długości ---\n",
    "# domyślnie pad_sequences uzupełnia zerami (czyli <pad>)\n",
    "sequences = pad_sequences(sentences, padding=\"post\")\n",
    "\n",
    "print(\"Sekwencje po paddingu:\\n\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d985559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 7, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Warstwa embedding ---\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=len(word_index),  # rozmiar słownika = 6 (liczymy też <pad>)\n",
    "    output_dim=4,               # każdy token będzie reprezentowany 4 liczbowymi współrzędnymi\n",
    "    mask_zero=True,             # bardzo ważne: ignoruj indeks 0 (czyli padding)\n",
    ")\n",
    "\n",
    "# --- Zastosowanie warstwy embedding ---\n",
    "embedded = embedding_layer(sequences)\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5e6cd-1daf-456f-a3c8-1dac11335388",
   "metadata": {},
   "source": [
    "Zwrócony tensor ma kształt `(batch, sequence_length, output_dim)`.\n",
    "\n",
    "Warstwę embedding można dalej połączyć z modelami sekwencyjnymi (LSTM, GRU) lub konwolucyjnymi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90da32",
   "metadata": {},
   "source": [
    "### Mini model z embeddingiem TensorFlow\n",
    "\n",
    "Poniżej prosty model klasyfikacji sentymentu złożony z embeddingu, warstwy global average pooling i gęstej warstwy wyjściowej.\n",
    "\n",
    "Warstwa global average pooling uśrednia wektory embeddingów wszystkich tokenów w zdaniu, tworząc jeden reprezentacyjny wektor zdania niezależny od jego długości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e97cf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │            \u001b[38;5;34m24\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index), output_dim=4, mask_zero=True),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "model_tf.build(input_shape=(None, 5))\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b0c2cc-e3db-484b-b78a-85e125ed5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kształt wejścia: (2, 5)\n",
      "Kształt po embeddingu: (2, 5, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[ 0.04715308,  0.04765863, -0.00378133, -0.00575564],\n",
       "        [ 0.02343799, -0.00236883,  0.00072575,  0.04583253],\n",
       "        [ 0.00855146, -0.03373616, -0.01493584, -0.01956507],\n",
       "        [-0.02337486, -0.02402957,  0.00608016, -0.0286571 ],\n",
       "        [-0.02337486, -0.02402957,  0.00608016, -0.0286571 ]],\n",
       "\n",
       "       [[-0.03246106, -0.04050843, -0.01969794,  0.01540457],\n",
       "        [ 0.02495016, -0.01543298, -0.03401797, -0.03365024],\n",
       "        [ 0.04715308,  0.04765863, -0.00378133, -0.00575564],\n",
       "        [-0.02337486, -0.02402957,  0.00608016, -0.0286571 ],\n",
       "        [-0.02337486, -0.02402957,  0.00608016, -0.0286571 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Załóżmy słownik o rozmiarze 6 (tokeny 0–5), embedding 4D\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=6, output_dim=4, mask_zero=True)\n",
    "\n",
    "# Przykładowe zdania zakodowane jako indeksy tokenów\n",
    "# 0 = padding\n",
    "sentences = np.array([\n",
    "    [1, 2, 3, 0, 0],   # zdanie 1: trzy tokeny + padding\n",
    "    [4, 5, 1, 0, 0],   # zdanie 2: dwa tokeny + padding\n",
    "])\n",
    "\n",
    "print(\"Kształt wejścia:\", sentences.shape)\n",
    "\n",
    "# Embedding\n",
    "embedded = embedding_layer(sentences)\n",
    "print(\"Kształt po embeddingu:\", embedded.shape)\n",
    "embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296f3b7-d10c-454f-a617-c5fe99ad7417",
   "metadata": {},
   "source": [
    "A więc 1 zdanie to taka macierz - coś takieggo (bedzie sie zmieniac przy uruchomieniach)\n",
    "\n",
    "        [[ 0.01423473, -0.00483084, -0.02746737, -0.02501923],  # 1\n",
    "        [ 0.02149788, -0.04756809, -0.04644064, -0.00472618],   # 2   \n",
    "        [ 0.00689582,  0.03334036, -0.00995095, -0.02848799],   # 3 \n",
    "        [-0.02906418, -0.01756475,  0.00183201,  0.03547058],   # 0\n",
    "        [-0.02906418, -0.01756475,  0.00183201,  0.03547058]]   # 0\n",
    "\n",
    "I pooling sumuje to kolumnami i liczy średnią - ale pomija to co jest naszym paddingiem\n",
    "\n",
    "To 1, 2, 3  nazywamy tokenami - czyli najmniejszymi porcjami tekstu, który rozumie nasz model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077413d2-8a68-47db-9eed-3a06eda2467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kształt po pooling: (2, 4)\n",
      "Wektor reprezentujący każde zdanie:\n",
      " [[ 0.02638084  0.00385122 -0.00599714  0.00683727]\n",
      " [ 0.01321406 -0.00276092 -0.01916575 -0.00800044]]\n"
     ]
    }
   ],
   "source": [
    "# Global Average Pooling\n",
    "pooled = tf.keras.layers.GlobalAveragePooling1D()(embedded)\n",
    "print(\"Kształt po pooling:\", pooled.shape)\n",
    "print(\"Wektor reprezentujący każde zdanie:\\n\", pooled.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a9e82-ddb8-4f3b-9452-1ae1a975312e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57cc3b9",
   "metadata": {},
   "source": [
    "### Embeddingi w PyTorch\n",
    "W PyTorch embeddingi tworzymy przez `torch.nn.Embedding(num_embeddings, embedding_dim)`. Przykład poniżej pokazuje pobieranie wektorów oraz prosty model klasyfikacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5f00ac-b89b-4bb6-8a17-34ae953c3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 5, 4]])\n",
      "Kształt: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# --- przykładowe zdania o różnej długości ---\n",
    "sentences = [\n",
    "    torch.tensor([1, 2]),          # \"lubię uczyć\"\n",
    "    torch.tensor([1, 2, 3, 4]),    # \"lubię uczyć się pytorch\"\n",
    "    torch.tensor([1, 2, 3, 5, 4])  # \"lubię uczyć się tensorflow pytorch\"\n",
    "]\n",
    "\n",
    "# --- padding ---\n",
    "# domyślnie padding jest z lewej (do najdłuższej sekwencji)\n",
    "seqences = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "\n",
    "print(seqences)\n",
    "print(\"Kształt:\", seqences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eac8381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(word_index), embedding_dim=4, padding_idx=0)\n",
    "embedded_torch = embedding(seqences)\n",
    "embedded_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db3a48-3449-4734-b9db-76ff9ddf79fc",
   "metadata": {},
   "source": [
    "Tu nasz batch_size to 3, najdłuższe zdanie ma 5 wyrazów a embedding ma wymiar 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c5b8d",
   "metadata": {},
   "source": [
    "#### Mini model z embeddingiem w PyTorch\n",
    "Poniższy moduł wykorzystuje warstwę embedding, uśrednia wektory wzdłuż sekwencji i przekazuje wynik do warstwy liniowej. To minimalny szkic klasyfikatora tekstu opartego na PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b05c77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleTextClassifier(\n",
       "  (embedding): Embedding(6, 4, padding_idx=0)\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (classifier): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq, embed_dim)\n",
    "        # zamieniamy na (batch, embed_dim, seq), aby użyć 1D pooling\n",
    "        pooled = self.pool(embedded.transpose(1, 2)).squeeze(-1)\n",
    "        logits = self.classifier(pooled)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "model_torch = SimpleTextClassifier(vocab_size=len(word_index), embed_dim=4)\n",
    "model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec75cbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5161],\n",
       "        [0.4880],\n",
       "        [0.5243]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model_torch(seqences)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5479ed",
   "metadata": {},
   "source": [
    "## 6. Dobre praktyki i wskazówki\n",
    "- Dobierz `embedding_dim` do wielkości słownika (zazwyczaj 16–300 dla prostych zadań NLP, więcej dla rekomendacji).\n",
    "- Używaj `padding_idx` (PyTorch) lub `mask_zero` (TensorFlow), jeśli w sekwencjach występują wartości wypełniające.\n",
    "- Możesz zacząć od losowej inicjalizacji i pozwolić modelowi uczyć się embeddingów lub wykorzystać embeddingi pretrenowane (np. FastText) i dostosować je (`fine-tuning`).\n",
    "- Analizuj embeddingi po treningu: wizualizuj PCA/TSNE, porównuj najbliższe wektory, by zweryfikować, czy model nauczył się semantyki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb3ec",
   "metadata": {},
   "source": [
    "## 7. Zastosowania embeddingów\n",
    "- Natural Language Processing (word embeddings, sentence embeddings, wektory dokumentów).\n",
    "- Systemy rekomendacji (embeddingi użytkowników i produktów).\n",
    "- Modele grafowe (Graph Embedding, Node2Vec).\n",
    "- Kodowanie zmiennych kategorycznych w modelach tablicowych (np. tabular deep learning).\n",
    "\n",
    "Embeddingi stanowią fundament nowoczesnych modeli, ponieważ pozwalają zamienić surowe kategorie na przestrzenie, w których łatwiej znaleźć wzorce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e8493-d12e-4229-ad24-64f4f1c20dae",
   "metadata": {},
   "source": [
    "## Przykład: embeddingi w prostym modelu\n",
    "\n",
    "Symulujemy prosty zbiór danych klientów:\n",
    "\n",
    "* **`region`** – kategoria (10 regionów, zakodowane jako liczby 0–9),\n",
    "* **`wiek`** – zmienna ciągła,\n",
    "* **`dochód`** – zmienna ciągła,\n",
    "* **`abonament`** – target (0/1, czy klient ma abonament).\n",
    "\n",
    "W typowym ML:\n",
    "\n",
    "* cechy ciągłe możemy podać „tak jak są” (po normalizacji/standaryzacji),\n",
    "* ale **cechy kategoryczne** (jak `region`) nie mają sensownego porządku → tu właśnie używamy **embeddingów**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38a4c2b-9a3b-4c1c-b390-156ab5f057a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ---------------------\n",
    "# 1. Dane przykładowe\n",
    "# ---------------------\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 500\n",
    "n_regions = 10  # kategorie regionów\n",
    "\n",
    "raw_data = pd.DataFrame({\n",
    "    # to są od razu indeksy kategorii wiec nie zamieniam juz tego na dane kategoryczne\n",
    "    # gdyby tu były jakies labelki - typu \"dolnosląski\", \"polnocno-zachodni\" itd to zamieniałbym\n",
    "    \"region\": np.random.randint(0, n_regions, size=n_samples),  \n",
    "    \"wiek\": np.random.randint(18, 70, size=n_samples),\n",
    "    \"dochód\": np.random.randint(2000, 12000, size=n_samples),\n",
    "    \"abonament\": np.random.randint(0, 2, size=n_samples)  # target: 0/1\n",
    "})\n",
    "\n",
    "categorical_cols = [\"region\"]\n",
    "continuous_cols = [\"wiek\", \"dochód\"]\n",
    "target_col = \"abonament\"\n",
    "\n",
    "X_cat = torch.tensor(raw_data[categorical_cols].values, dtype=torch.long)\n",
    "X_cont = torch.tensor(raw_data[continuous_cols].values, dtype=torch.float32)\n",
    "y = torch.tensor(raw_data[target_col].values, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d21305-851d-4520-8bb9-bc4705bd0508",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Model\n",
    "\n",
    "* Dla cechy kategorycznej `region` uczymy **embedding** o wymiarze 6 (czyli każdemu regionowi odpowiada wektor długości 6).\n",
    "* Dla cech ciągłych (`wiek`, `dochód`) stosujemy prostą warstwę liniową, aby dopasować skalę.\n",
    "* Oba wektory (embedding + cechy ciągłe) są łączone i wysyłane do sieci neuronowej, która przewiduje `abonament`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8b81c4-ded3-47f4-9cac-043c37f91b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 2. Model z embeddingami\n",
    "# ---------------------\n",
    "class CustomerModel(nn.Module):\n",
    "    def __init__(self, n_regions, emb_dim, n_cont):\n",
    "        super().__init__()\n",
    "        # embedding dla zmiennej kategorycznej \"region\" - wartość będzie podana przy inicjalizacji\n",
    "        self.emb = nn.Embedding(n_regions, emb_dim)\n",
    "        # warstwa dla cech ciągłych\n",
    "        self.fc_cont = nn.Linear(n_cont, 4)\n",
    "        # klasyfikator końcowy\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim + 4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x_emb = self.emb(x_cat).squeeze(1)        # embedding regionu\n",
    "        x_cont = self.fc_cont(x_cont)             # przekształcone dane ciągłe\n",
    "        x = torch.cat([x_emb, x_cont], dim=1)     # połączenie\n",
    "        return self.fc(x)\n",
    "\n",
    "model = CustomerModel(n_regions=n_regions, emb_dim=6, n_cont=len(continuous_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4ef6f-526f-460f-82dc-309ca1f49378",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Trening\n",
    "\n",
    "Model uczy się end-to-end:\n",
    "\n",
    "* embeddingi regionów są **parametrami sieci**,\n",
    "* w trakcie treningu są aktualizowane, aby jak najlepiej pomagały w przewidywaniu abonamentu.\n",
    "\n",
    "W praktyce oznacza to: **regiony, które w podobny sposób wpływają na prawdopodobieństwo posiadania abonamentu, będą miały embeddingi bliżej siebie w przestrzeni wektorowej**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77575e7c-995d-4937-934b-4a665e4b7dc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Analiza embeddingów\n",
    "\n",
    "Po treningu wyciągamy macierz embeddingów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e783bb99-86a4-48b6-94c4-368d510fb700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0035288 , -1.8294208 , -0.04876269,  1.2405039 , -0.9325821 ,\n",
       "        1.5356361 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.emb.weight.detach().numpy()\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98180006-78c4-4ddd-9e2c-27b8be1e53a5",
   "metadata": {},
   "source": [
    "* kształt = `10 x 6` (10 regionów, embedding_dim=6),\n",
    "* każda linia = wektor opisujący dany region. Ten wektor ma 6 współrzędnych.\n",
    "\n",
    "Aby je zobaczyć:\n",
    "\n",
    "* redukujemy wymiar do 2D przy pomocy PCA,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce5d37-d7cd-4441-9f3f-bdb5f6bb7442",
   "metadata": {},
   "source": [
    "### PCA — Principal Component Analysis (Analiza Głównych Składowych)\n",
    "\n",
    "Metoda redukcji wymiaru, która przekształca dane do nowej przestrzeni współrzędnych,\n",
    "tak aby **pierwsze składowe** przechwytywały jak najwięcej wariancji w danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848be7fa-4568-4bb8-bd6b-9d9e5f3e805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1005371 , -0.25924316], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "embeddings_2d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05d508-773f-4fc5-9e5b-7353883944f9",
   "metadata": {},
   "source": [
    "* rysujemy punkty odpowiadające regionom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c11142e8-ae2b-48fa-af5a-00ed9b05d7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=range(n_regions), cmap=\"tab10\", s=80)\n",
    "\n",
    "for i in range(n_regions):\n",
    "    plt.annotate(f\"region {i}\", (embeddings_2d[i, 0]+0.02, embeddings_2d[i, 1]+0.02))\n",
    "\n",
    "plt.title(\"Embeddingi regionów (PCA do 2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa68ad-9892-485b-bff1-15c649a10125",
   "metadata": {},
   "source": [
    "Wykres pokazuje, że **niektóre regiony grupują się bliżej siebie** — czyli model „uznał”, że są podobne z punktu widzenia abonamentu.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Wnioski i korzyści z embeddingów\n",
    "\n",
    "1. **Redukcja wymiarowości**\n",
    "\n",
    "   * Zamiast one-hot (10 kategorii → wektor długości 10), używamy embeddingów (np. wymiar 6).\n",
    "   * Przy większych słownikach (np. 1000 kategorii) oszczędność jest ogromna.\n",
    "\n",
    "2. **Uchwycenie podobieństw**\n",
    "\n",
    "   * W one-hot wszystkie kategorie są „równie odległe”.\n",
    "   * Embeddingi pozwalają modelowi samodzielnie nauczyć się, które kategorie są podobne.\n",
    "   * Np. regiony o podobnej strukturze klientów będą mieć wektory bliżej siebie.\n",
    "\n",
    "3. **Uczą się razem z modelem**\n",
    "\n",
    "   * Nie musimy ręcznie kodować relacji między kategoriami.\n",
    "   * Model sam znajdzie najlepszą reprezentację dla danego zadania.\n",
    "\n",
    "4. **Łatwość analizy**\n",
    "\n",
    "   * Po treningu embeddingi można interpretować:\n",
    "\n",
    "     * grupować kategorie,\n",
    "     * wizualizować (PCA/t-SNE/UMAP),\n",
    "     * szukać najbliższych sąsiadów (np. „które regiony są najbardziej podobne?”).\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Podsumowanie**:\n",
    "W tym przykładzie embedding pozwala traktować **region** nie jako arbitralny numer, lecz jako **punkt w przestrzeni wektorowej**, gdzie bliskość oznacza podobieństwo w kontekście abonamentu. Dzięki temu model uczy się szybciej, ma mniej parametrów i potrafi generalizować lepiej niż przy gołym one-hot encodingu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a539c-dede-4b61-9213-5f007f73e558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4fb6e5-456d-479c-86d5-631ead71cb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
