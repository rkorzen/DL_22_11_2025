{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcef63c7",
   "metadata": {},
   "source": [
    "# Zapisywanie i wczytywanie modeli w TensorFlow\n",
    "\n",
    "Poniższy przykład pokazuje kompletny przepływ pracy: tworzymy prosty model sieci neuronowej w TensorFlow, trenujemy go na sztucznych danych, zapisujemy na dysku, a następnie wczytujemy i wykorzystujemy do predykcji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9e4d0",
   "metadata": {},
   "source": [
    "## 1. Importy i przygotowanie danych\n",
    "Zaczynamy od importu TensorFlow oraz przygotowania niewielkiego zbioru danych (syntetyczna regresja liniowa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Ustawienie ziarna losowego dla powtarzalności\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dane wejściowe (x) i wyjście (y)\n",
    "x = np.linspace(-1, 1, 200)\n",
    "y = 3 * x + 2 + np.random.normal(0, 0.2, size=x.shape)\n",
    "\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd122aa",
   "metadata": {},
   "source": [
    "## 2. Definicja i kompilacja modelu\n",
    "Tworzymy prosty model sekwencyjny z jedną warstwą gęstą oraz definiujemy funkcję straty i optymalizator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60242a8",
   "metadata": {},
   "source": [
    "## 3. Trening modelu\n",
    "Trenujemy model przez kilka epok, by dopasował się do danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, y, epochs=200, verbose=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss podczas treningu')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c52c2",
   "metadata": {},
   "source": [
    "## 4. Zapis modelu\n",
    "TensorFlow pozwala zapisać model w formacie SavedModel lub jako plik HDF5. Poniżej pokazujemy obie opcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel_path = 'saved_model_tf'\n",
    "hdf5_path = 'model.h5'\n",
    "\n",
    "model.save(savedmodel_path)\n",
    "model.save(hdf5_path)\n",
    "\n",
    "print('Zapisano model w katalogu', savedmodel_path)\n",
    "print('Zapisano model do pliku', hdf5_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8032f4f",
   "metadata": {},
   "source": [
    "## 5. Wczytanie modelu\n",
    "Wczytujemy model z dysku i wykorzystujemy go do predykcji na nowych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(savedmodel_path)\n",
    "loaded_model_h5 = tf.keras.models.load_model(hdf5_path)\n",
    "\n",
    "# Dane testowe\n",
    "x_test = np.array([[-0.5], [0.0], [0.5]])\n",
    "predictions = loaded_model.predict(x_test)\n",
    "predictions_h5 = loaded_model_h5.predict(x_test)\n",
    "\n",
    "print('Predykcje (SavedModel):', predictions.flatten())\n",
    "print('Predykcje (HDF5):', predictions_h5.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd824e7",
   "metadata": {},
   "source": [
    "## 6. Walidacja spójności\n",
    "Sprawdzamy, czy parametry wczytanych modeli odpowiadają oryginalnemu modelowi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23014c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porównujemy wagi\n",
    "original_weights = model.get_weights()\n",
    "loaded_weights = loaded_model.get_weights()\n",
    "loaded_weights_h5 = loaded_model_h5.get_weights()\n",
    "\n",
    "print('Czy wagi SavedModel są identyczne?', all(np.allclose(o, l) for o, l in zip(original_weights, loaded_weights)))\n",
    "print('Czy wagi HDF5 są identyczne?', all(np.allclose(o, l) for o, l in zip(original_weights, loaded_weights_h5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2aefb8",
   "metadata": {},
   "source": [
    "## 7. Podsumowanie\n",
    "1. Zbudowaliśmy i wytrenowaliśmy prosty model w TensorFlow.\n",
    "2. Zapisaliśmy model w dwóch formatach (`SavedModel`, `HDF5`).\n",
    "3. Wczytaliśmy model z dysku i wykorzystaliśmy go do predykcji.\n",
    "4. Porównaliśmy wagi, aby upewnić się, że wczytane modele zachowują spójność z oryginałem.\n",
    "\n",
    "Ten schemat możesz wykorzystać w swoich projektach, zastępując model oraz dane własnymi zasobami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}